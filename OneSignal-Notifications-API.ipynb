{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime, date, timedelta\n",
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime, date, timedelta\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "#Query Details that is passed in the URL\n",
    "limit = '50'\n",
    "offset = '50'\n",
    "total_count = 'true'\n",
    "\n",
    "#Create an empty list\n",
    "all_items = []\n",
    "\n",
    "\n",
    "def get():\n",
    "\n",
    "\n",
    "\n",
    "    url_address=\"https://onesignal.com/api/v1/notifications?app_id={enter-app-id-here}&kind=0&limit=0&offset=\"+str('0')\n",
    "    header = {\"Content-Type\": \"application/json; charset=utf-8\",\n",
    "              \"Authorization\": \"Basic {enter-api-key-here}\"}\n",
    "\n",
    "\n",
    "    querystring = {\"limit\":limit, \"total_count\":total_count}\n",
    "\n",
    "\n",
    "    # find out total number of items\n",
    "    r = requests.get(url=url_address, headers=header, params=querystring).json()\n",
    "    total_record = int(r['total_count'])\n",
    "    print(\"Total record: \" +str(total_record))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # loop through all offset and return JSON object\n",
    "    for offset in range(0, 100, 50):\n",
    "        url = \"https://onesignal.com/api/v1/notifications?app_id={enter-app-id-here}&kind=0&limit=0&offset=\"+str(offset)              \n",
    "        response = requests.get(url=url,headers=header, params=querystring).json()        \n",
    "        all_items.append(response) \n",
    "        data = json_normalize(all_items, record_path='notifications')\n",
    "        print(offset)\n",
    "    \n",
    "\n",
    "    # prettify JSON\n",
    "    data = json.dumps(all_items, sort_keys=True, indent=4)\n",
    "\n",
    "    return data\n",
    "\n",
    "print(get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Flatten response above by using json normalize\n",
    "df= pd.json_normalize(all_items)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save response in df to a json file called notifications.json\n",
    "with open(\"notifications.json\", \"w\") as outfile: \n",
    "    json.dump(all_items, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open nested df\n",
    "with open('notifications.json') as data_file:    \n",
    "    data = json.load(data_file)  \n",
    "\n",
    "df = pd.json_normalize(data, 'notifications', ['completed_at', 'converted', 'received','successful'], \n",
    "                    record_prefix='notifications_', errors='ignore')\n",
    "\n",
    "\n",
    "#replace empty values with o\n",
    "df=df.fillna(0)\n",
    "\n",
    "# Convert from unix to datetime\n",
    "df['notifications_completed_at'] = pd.to_datetime(df['notifications_completed_at'],unit='s')\n",
    "\n",
    "#remove timestamp from date\n",
    "df['notifications_completed_at'] = pd.to_datetime(df['notifications_completed_at']).dt.date\n",
    "\n",
    "#Pull only specific metrics\n",
    "df=df.loc[:,['notifications_completed_at','notifications_received','notifications_converted','notifications_successful']]\n",
    "\n",
    "# save dataframe to CSV again\n",
    "dfcsv=df.to_csv('notifications.csv')\n",
    "\n",
    "#Groupby date\n",
    "df=df.groupby(['notifications_completed_at']).sum()\n",
    "\n",
    "#Create dataframe\n",
    "df=pd.DataFrame(df)\n",
    "\n",
    "#Create brandname to differentiate data from one appid to another. Here, I am creating a column called \"name\" and assigning it whatever name I'll decide on\n",
    "df['name'] = '{name-of-column}'\n",
    "\n",
    "#Store in csv\n",
    "\n",
    "df=df.to_csv('notifications.csv')\n",
    "\n",
    "#Read CSV\n",
    "df=pd.read_csv('notifications.csv')\n",
    "\n",
    "# df1=df['notifications_completed_at'].iloc[-1]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
